%{
/*
 * URL-based Specification Language (USL) Lexical Analyzer
 * LEX Specification File for USL Compiler
 * 
 * This file defines the lexical structure of USL including:
 * - Keywords (url, title, description, etc.)
 * - Identifiers and variable references
 * - String literals with interpolation
 * - Operators and delimiters
 * - Comments
 */
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include "usl.tab.h"  /* Generated by YACC */

/* Global variables for line and column tracking */
int line_number = 1;
int column_number = 1;

/* Lexical Error Table Structure */
#define MAX_LEX_ERRORS 100

typedef struct {
    int line;
    int column;
    char character;
    char message[100];
} LexicalError;

LexicalError error_table[MAX_LEX_ERRORS];
int error_count = 0;

/* Token Table Structure */
#define MAX_TOKENS 1000

typedef struct {
    int sr_no;
    int line;
    char type[30];
    char lexeme[100];
    char value[100];
} TokenEntry;

TokenEntry token_table[MAX_TOKENS];
int token_table_count = 0;

/* Function prototypes */
void update_location();
void print_token(char* token_name, char* token_value);
void record_lexical_error(int line, int col, char ch, const char* msg);
void print_lexical_error_table();
void record_token(const char* type, const char* lexeme, const char* value);
void print_token_table();

/* Token counting for statistics */
int token_count = 0;

%}

/* LEX Options */
%option yylineno
%option noyywrap

/* Regular Expression Definitions */
DIGIT           [0-9]
LETTER          [a-zA-Z]
IDENTIFIER      [a-zA-Z]([a-zA-Z0-9_])*
WHITESPACE      [ \t\r]+
NEWLINE         \n
STRING_CHAR     [^"\\\n]
ESCAPE_CHAR     \\[ntr"\\]
COMMENT_CHAR    [^\n]*

/* Start Conditions for String Parsing */
%x STRING_STATE
%x COMMENT_STATE

%%

    /* Comments - Single line starting with # */
#                       { BEGIN(COMMENT_STATE); }
<COMMENT_STATE>{COMMENT_CHAR}   { /* Consume comment text */ }
<COMMENT_STATE>{NEWLINE}        { 
                                  line_number++; 
                                  column_number = 1; 
                                  BEGIN(INITIAL); 
                                  /* Skip newlines after comments */
                                }

    /* Keywords */
"if"                    { update_location(); print_token("IF", yytext); return IF; }
"else"                  { update_location(); print_token("ELSE", yytext); return ELSE; }
"url"                   { update_location(); print_token("URL", yytext); return URL; }
"title"                 { update_location(); print_token("TITLE", yytext); return TITLE; }
"description"           { update_location(); print_token("DESCRIPTION", yytext); return DESCRIPTION; }
"template"              { update_location(); print_token("TEMPLATE", yytext); return TEMPLATE; }
"access"                { update_location(); print_token("ACCESS", yytext); return ACCESS; }
"seo"                   { update_location(); print_token("SEO", yytext); return SEO; }
"meta_tags"             { update_location(); print_token("META_TAGS", yytext); return META_TAGS; }
"navigation"            { update_location(); print_token("NAVIGATION", yytext); return NAVIGATION; }
"links"                 { update_location(); print_token("LINKS", yytext); return LINKS; }
"footer"                { update_location(); print_token("FOOTER", yytext); return FOOTER; }
"text"                  { update_location(); print_token("TEXT", yytext); return TEXT; }
"generate_content"      { update_location(); print_token("GENERATE_CONTENT", yytext); return GENERATE_CONTENT; }
"redirect"              { update_location(); print_token("REDIRECT", yytext); return REDIRECT; }
"keywords"              { update_location(); print_token("KEYWORDS", yytext); return KEYWORDS; }

    /* Operators and Delimiters */
"="                     { update_location(); print_token("ASSIGN", yytext); return ASSIGN; }
"{"                     { update_location(); print_token("LBRACE", yytext); return LBRACE; }
"}"                     { update_location(); print_token("RBRACE", yytext); return RBRACE; }
"("                     { update_location(); print_token("LPAREN", yytext); return LPAREN; }
")"                     { update_location(); print_token("RPAREN", yytext); return RPAREN; }
","                     { update_location(); print_token("COMMA", yytext); return COMMA; }
":"                     { update_location(); print_token("COLON", yytext); return COLON; }
"."                     { update_location(); print_token("DOT", yytext); return DOT; }
"/"                     { record_lexical_error(line_number, column_number, '/', "Forward slash not allowed in identifiers or property names"); column_number++; }

    /* Variable References */
\${IDENTIFIER}          { 
                          update_location(); 
                          yylval.string_val = _strdup(yytext + 1); /* Skip the $ */
                          print_token("VARIABLE_REF", yylval.string_val); 
                          return VARIABLE_REF; 
                        }

    /* String Literals */
\"                      { BEGIN(STRING_STATE); yymore(); }
'                       { record_lexical_error(line_number, column_number, '\'', "Single quotes not allowed, use double quotes for strings"); column_number++; }
<STRING_STATE>\"        { 
                          BEGIN(INITIAL); 
                          update_location();
                          /* Remove quotes and store string value */
                          yytext[yyleng-1] = '\0';
                          yylval.string_val = _strdup(yytext + 1);
                          print_token("STRING_LITERAL", yylval.string_val);
                          return STRING_LITERAL; 
                        }
<STRING_STATE>{STRING_CHAR}+    { yymore(); }
<STRING_STATE>{ESCAPE_CHAR}     { yymore(); }
<STRING_STATE>{NEWLINE}         { 
                                  line_number++; 
                                  column_number = 1; 
                                  yymore(); 
                                }
<STRING_STATE><<EOF>>           { 
                                  record_lexical_error(line_number, column_number, '"', "Unterminated string literal");
                                  BEGIN(INITIAL);
                                  return ERROR_TOKEN;
                                }

    /* URL Patterns (strings with path parameters) */
\"\/[^"]*\{[^}]+\}[^"]*\"       {
                                  update_location();
                                  /* Remove quotes */
                                  yytext[yyleng-1] = '\0';
                                  yylval.string_val = _strdup(yytext + 1);
                                  print_token("URL_PATTERN", yylval.string_val);
                                  return URL_PATTERN;
                                }

    /* Identifiers */
{IDENTIFIER}            { 
                          update_location(); 
                          /* Look ahead to check if this identifier is part of a valid assignment */
                          /* We can't do full lookahead in lex, so we'll rely on parser for missing = */
                          /* But we can validate the identifier format */
                          /* This will be handled by parser, but we can validate identifier format */
                          /* Ensure identifier doesn't contain invalid characters */
                          for (int i = 0; i < yyleng; i++) {
                              if (yytext[i] == '/' || yytext[i] == '\\' || yytext[i] == '"' || yytext[i] == '\'' || 
                                  (yytext[i] < 32) || (yytext[i] > 126)) {
                                  record_lexical_error(line_number, column_number + i, yytext[i], "Invalid character in identifier");
                              }
                          }
                          yylval.string_val = _strdup(yytext);
                          print_token("IDENTIFIER", yylval.string_val); 
                          return IDENTIFIER; 
                        }

    /* Numbers */
{DIGIT}+                { 
                          update_location(); 
                          yylval.int_val = atoi(yytext);
                          print_token("NUMBER", yytext); 
                          return NUMBER; 
                        }

    /* Whitespace */
{WHITESPACE}            { 
                          column_number += yyleng; 
                          /* Skip whitespace */ 
                        }

    /* Newlines */
{NEWLINE}               { 
                          line_number++; 
                          column_number = 1; 
                          /* Skip newlines - don't return token to parser */
                        }

    /* Error handling for unrecognized characters */
.                       { 
                          record_lexical_error(line_number, column_number, yytext[0], "Unrecognized character");
                          column_number++;
                          /* Continue lexing instead of returning ERROR_TOKEN */
                          yymore();  /* Include this character in next token attempt */
                        }

%%

/* User Code Section */

void update_location() {
    column_number += yyleng;
    token_count++;
}

void print_token(char* token_name, char* token_value) {
    #ifdef DEBUG_LEXER
    printf("Token: %-15s Value: %-20s Line: %d, Column: %d\n", 
           token_name, token_value, line_number, column_number - yyleng);
    #endif
    
    /* Record token in token table */
    record_token(token_name, yytext, token_value);
}

/* Function to record tokens in token table */
void record_token(const char* type, const char* lexeme, const char* value) {
    if (token_table_count < MAX_TOKENS) {
        token_table[token_table_count].sr_no = token_table_count + 1;
        token_table[token_table_count].line = line_number;
        strncpy(token_table[token_table_count].type, type, 29);
        token_table[token_table_count].type[29] = '\0';
        strncpy(token_table[token_table_count].lexeme, lexeme, 99);
        token_table[token_table_count].lexeme[99] = '\0';
        strncpy(token_table[token_table_count].value, value ? value : lexeme, 99);
        token_table[token_table_count].value[99] = '\0';
        token_table_count++;
    }
}

/* Function to print token table */
void print_token_table() {
    printf("\n");
    printf("==========================================================================================================\n");
    printf("    Token Table\n");
    printf("==========================================================================================================\n");
    
    if (token_table_count == 0) {
        printf("No tokens found.\n");
    } else {
        printf("%-8s %-8s %-20s %-30s %-30s\n", "Sr.No.", "Line", "Type", "Lexeme", "Value");
        printf("----------------------------------------------------------------------------------------------------------\n");
        
        for (int i = 0; i < token_table_count; i++) {
            printf("%-8d %-8d %-20s %-30s %-30s\n",
                   token_table[i].sr_no,
                   token_table[i].line,
                   token_table[i].type,
                   token_table[i].lexeme,
                   token_table[i].value);
        }
        
        printf("----------------------------------------------------------------------------------------------------------\n");
        printf("Total Tokens: %d\n", token_table_count);
    }
    printf("==========================================================================================================\n");
}

/* Function to record lexical errors */
void record_lexical_error(int line, int col, char ch, const char* msg) {
    if (error_count < MAX_LEX_ERRORS) {
        error_table[error_count].line = line;
        error_table[error_count].column = col;
        error_table[error_count].character = ch;
        strncpy(error_table[error_count].message, msg, 99);
        error_table[error_count].message[99] = '\0';
        error_count++;
    }
}

/* Function to print lexical error table */
void print_lexical_error_table() {
    printf("\n");
    printf("==========================================\n");
    printf("    Lexical Errors\n");
    printf("==========================================\n");
    
    if (error_count == 0) {
        printf("No lexical errors detected.\n");
    } else {
        printf("%-8s %-10s %-30s %-10s\n", "Line", "Column", "Message", "Character");
        printf("------------------------------------------------------------\n");
        for (int i = 0; i < error_count; i++) {
            char ch_display[10];
            if (error_table[i].character == '\n') {
                strcpy(ch_display, "\\n");
            } else if (error_table[i].character == '\t') {
                strcpy(ch_display, "\\t");
            } else if (error_table[i].character == '\r') {
                strcpy(ch_display, "\\r");
            } else if (error_table[i].character < 32 || error_table[i].character > 126) {
                sprintf(ch_display, "0x%02X", (unsigned char)error_table[i].character);
            } else {
                sprintf(ch_display, "'%c'", error_table[i].character);
            }
            printf("%-8d %-10d %-30s %-10s\n", 
                   error_table[i].line, 
                   error_table[i].column,
                   error_table[i].message,
                   ch_display);
        }
    }
    printf("==========================================\n");
}

/* Function to reset lexer state */
void reset_lexer() {
    line_number = 1;
    column_number = 1;
    token_count = 0;
    error_count = 0;
    token_table_count = 0;
}

/* Function to get lexer statistics */
void print_lexer_stats() {
    printf("\n=== Lexical Analysis Statistics ===\n");
    printf("Total tokens processed: %d\n", token_count);
    printf("Total lines processed: %d\n", line_number);
    printf("===================================\n");
}

/* Main function for standalone lexer testing */
#ifdef STANDALONE_LEXER
int main(int argc, char* argv[]) {
    FILE* input_file;
    
    if (argc > 1) {
        input_file = fopen(argv[1], "r");
        if (!input_file) {
            fprintf(stderr, "Error: Cannot open file %s\n", argv[1]);
            return 1;
        }
        yyin = input_file;
    } else {
        printf("USL Lexical Analyzer - Enter USL code (Ctrl+D to end):\n");
        yyin = stdin;
    }
    
    printf("\n=== Starting Lexical Analysis ===\n");
    
    int token;
    while ((token = yylex()) != 0) {
        if (token == ERROR_TOKEN) {
            fprintf(stderr, "Lexical analysis failed due to errors.\n");
            return 1;
        }
    }
    
    print_lexer_stats();
    
    if (argc > 1) {
        fclose(input_file);
    }
    
    return 0;
}
#endif